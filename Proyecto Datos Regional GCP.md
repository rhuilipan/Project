# Dise√±o de Plataforma de Datos Federada ‚Äì Google Cloud Platform en Global Airline Group

### **Proyecto**: Plataforma Federada de Ingesta y Procesamiento de Datos
### **Fecha**: Abril 2025

## √çndice Propuesto ‚Äì Documento de Proyecto Plataforma Federada

1. [Introducci√≥n](#introduccion)

2. [Problem√°tica](#problematica)

3. [Soluci√≥n Propuesta](#solucion-propuesta)

4. [Diagrama Soluci√≥n](#diagrama-solucion)
    
5. [Flujo de Datos](#flujo-de-datos)

6. [Servicios y Costos Estimados](#servicios-y-costos-estimados)

7. [Conclusi√≥n y Recomendaciones](#conclusion-y-recomendaciones)

## Introducci√≥n

El presente documento detalla la propuesta de dise√±o, planificaci√≥n y ejecuci√≥n para una plataforma federada de datos en Google Cloud Platform, adaptada al contexto de una organizaci√≥n global del sector aeron√°utico. En la actualidad, los datos operativos, comerciales y de experiencia del cliente se encuentran dispersos en m√∫ltiples regiones, proyectos y sistemas. Esto dificulta la generaci√≥n de m√©tricas consistentes, retrasa la toma de decisiones y limita el uso avanzado de datos (machine learning, personalizaci√≥n, etc.). El objetivo del proyecto es dise√±ar una soluci√≥n t√©cnica y organizacional que habilite la integraci√≥n de datos multirregi√≥n con un enfoque moderno, gobernado y orientado al autoservicio, utilizando capacidades nativas de GCP como BigQuery, Dataflow, Dataplex, Pub/Sub, y otros.

---

## Problem√°tica

Actualmente, la organizaci√≥n enfrenta las siguentes problem√°ticas:

- **Silos de datos regionales** en m√∫ltiples proyectos GCP o fuera de estos.
- **Esquemas inconsistentes** entre fuentes.
- Latencias elevadas en an√°lisis multi-regi√≥n.
- Costos crecientes por replicaci√≥n manual o soluciones ad-hoc.
- Falta de trazabilidad y unificaci√≥n del modelo de datos global.

---

## Soluci√≥n Propuesta

Antes de empezar con la soluci√≥n t√©cnica, es indispensable iniciar con una serie de reuniones de descubrimiento regional que permitan entender las particularidades operativas y anal√≠ticas de cada zona, complementadas con un mapa de madurez de datos que identifique brechas, oportunidades y estructuras de esquemas. La arquitectura ser√° co-creada en conjunto con un **Data Platform Council ***, conformado por l√≠deres t√©cnicos regionales y representantes del proveedor cloud, asegurando alineaci√≥n, sostenibilidad y adopci√≥n temprana. La ejecuci√≥n se realizar√° mediante un modelo iterativo e incremental, entregando valor tangible en cada sprint y promoviendo visibilidad continua a trav√©s de demos quincenales y entornos de prueba ("sandbox") para usuarios clave, garantizando as√≠ una evoluci√≥n org√°nica y colaborativa del proyecto.

Se propone una **arquitectura federada**, que permita ingestar, catalogar y procesar datos provenientes de BigQuery, Cloud Storage y CloudSQL en m√∫ltiples regiones de GCP, soportando flujos en **tiempo real y batch**, con herramientas nativas para gobernanza, eficiencia y an√°lisis avanzado.

---

### Diagrama Soluci√≥n
La soluci√≥n propuesta se visualiza en el siguiente diagrama:



#### üó∫Ô∏è Arquitectura de la Plataforma Federada de Datos ‚Äì GCP

### üåç Regi√≥n A / Proyecto Regional
```
+-------------------------------------------------------------+
|                 GCP Project: Region A (ej. us-east1)        |
|                                                             |
|  +-----------+    +--------------+    +-----------+         |
|  | CloudSQL  |    | CloudStorage |    | BigQuery  |         |
|  +-----+-----+    +------+-------+    +-----+-----+         |
|        |                 |                  |               |
|   +----v----+     +------v------+     +-----v-----+         |
|   | Dataflow|     |   Pub/Sub   |     |EXPORT DATA|         |
|   +---------+     +-------------+     +-----------+         |
+-------------------------------------------------------------+
              |                          |
              v                          v
        (Transformaci√≥n)         (Eventos disparadores)

```
### üß¨ Plataforma Central ‚Äì Curaci√≥n y Federaci√≥n
```
+-------------------------------------------------------------+
|                GCP Proyecto Centralizado (shared/core)      |
|                                                             |
|  +-----------------------+    +--------------------------+  |
|  | Curated BQ Datasets   |    | External Tables (SQL/CS) |  |
|  +----------+------------+    +------------+-------------+  |
|             v                              v                |
|       +-------------+          +---------------------+      |
|       | Materialized|<-------->|  EXTERNAL_QUERY()   |      |
|       |   Views     |          +---------------------+      |
|       +------+------+
|              v
|  +--------------------------+
|  | BI Engine + Looker Studio|
|  +--------------------------+
+-------------------------------------------------------------+
```

### Gobernanza, Metadatos y Seguridad
```
+-------------------------------------------------------------+
|                  Gobernanza y Control                       |
|  +------------+  +--------------+  +----------------------+ |
|  |  Dataplex  |  | Data Catalog |  | IAM / Monitoring     | |
|  | (zonas     |  | (metadatos)  |  | Auditor√≠a / Roles    | |
|  |  raw/etc)  |  +--------------+  +----------------------+ |
+-------------------------------------------------------------+
```

## Automatizaci√≥n y Orquestaci√≥n
```
+-------------------------------------------------------------+
|                    Automatizaci√≥n                           |
|  +------------+  +----------------+  +---------------------+|
|  | Cloud Build|  | Cloud Scheduler|  | Terraform (IaC)     ||
|  +------------+  +----------------+  +---------------------+|
+-------------------------------------------------------------+
```


La soluci√≥n incluye los siguientes componentes:
*: cloud ran es gratis es para hacer api rest chicas: es serverless.
*: flask 

- **Cloud Pub/Sub**: canal de ingesti√≥n de eventos para procesamiento en tiempo real.
- **Cloud Functions**: disparadores ligeros para automatizaci√≥n basada en eventos.
- **Cloud Dataflow**: procesamiento ETL/ELT en batch y streaming.
- **Cloud Storage**: zona de datos crudos y almacenamiento intermedio.
- **BigQuery**: motor principal de almacenamiento anal√≠tico y federaci√≥n SQL.
- **BigQuery Omni** (opcional): consultas entre nubes o regiones remotas.
- **Dataplex**: gobernanza de datos y definici√≥n de zonas (raw, curado, anal√≠tico).
- **Data Catalog**: cat√°logo de metadatos y control de versiones de esquemas.
- **Looker / BI Engine**: visualizaci√≥n y an√°lisis de alto rendimiento.

---

### Flujo de Datos

1. **Captura**
   - **CloudSQL (PostgreSQL)**: extra√≠do con Dataflow v√≠a JDBC.
   - **Cloud Storage**: eventos `OBJECT_FINALIZE` disparan funciones para ETL.
   - **BigQuery**: datasets regionales exportados con `EXPORT DATA`.

2. **Ingesta**
   - Archivos aterrizan en buckets por regi√≥n/domino (`raw/region_x/...`).
   - Cloud Dataflow mueve datos a BigQuery y los transforma.

3. **Procesamiento**
   - Transformaci√≥n y normalizaci√≥n de esquemas.
   - Aplicaci√≥n de reglas de negocio (e.g., conversi√≥n de monedas, unificaci√≥n de columnas).
   - Consolidaci√≥n en datasets curados listos para an√°lisis.

4. **Federaci√≥n y Consumo**
   - Consultas SQL desde BigQuery entre regiones o proyectos.
   - Materializaci√≥n de vistas para KPIs de alta demanda.
   - Dashboards en Looker / Data Studio con acceso controlado.

---

## Servicios y Costos Estimados

| Servicio              | Rol en la Arquitectura | Estimaci√≥n Mensual (USD) |
|-----------------------|-------------------------|---------------------------|
| **Cloud Pub/Sub**     | Ingesta de eventos      | $10 ‚Äì $20                 |
| **Cloud Functions**   | Disparadores            | $5 ‚Äì $15                  |
| **Cloud Storage**     | 10 TB (landing/raw)     | $100 ‚Äì $150               |
| **CloudSQL**          | PostgreSQL regional     | $200 ‚Äì $500               |
| **Cloud Dataflow**    | Procesamiento diario    | $500 ‚Äì $1,200             |
| **BigQuery**          | 10 TB almacenados + 5 TB consultados | $400 ‚Äì $800 |
| **BigQuery Omni**     | Opcional (multi-cloud)  | $100 ‚Äì $300               |
| **Dataplex / Catalog**| Gobernanza, metadatos   | Sin costo directo         |
| **Looker / Studio**   | BI y dashboards         | Incluido (seg√∫n plan)     |

> ‚ö†Ô∏è Los costos var√≠an seg√∫n el volumen de datos, frecuencia de consulta, y ubicaci√≥n regional. Se recomienda aplicar pr√°cticas como **particionado, clustering y uso de vistas materializadas** para optimizar.

---

## Gobernanza y Consistencia

- **Dataplex** se usar√° para definir zonas de datos: `raw`, `curated`, `analytics`.
- **Data Catalog** permite clasificar y versionar esquemas.
- Los pipelines incorporan validaci√≥n de esquema antes de cargar datos.
- Uso de JSON schemas versionados con Git para asegurar integridad en transformaciones.

---

## Estrategias de Optimizaci√≥n
- **Vistas materializadas** para reducir consultas interregionales costosas.
- **BI Engine** para acelerar dashboards con cach√© en memoria.
- **Job scheduling** de agregaciones pesadas en horarios de baja demanda.
- **Dataflow autoscaling** para adaptarse al volumen din√°mico.

---

## Riesgos y Mitigaciones

| Riesgo                        | Mitigaci√≥n                                   |
|------------------------------|----------------------------------------------|
| Latencia entre regiones      | Caching + vistas materializadas              |
| Cambios en esquemas fuente   | Validaci√≥n autom√°tica + versionado de esquema |
| Costos de escaneo elevado    | Particionado + Clustering + vistas agregadas |
| Fallos en pipelines          | Alertas + retries + DLQ con Pub/Sub          |

---

## Recomendaciones
- Establecer un proyecto ‚Äúcore‚Äù para almacenamiento y consumo central.
- Aplicar IaC (Terraform) para replicabilidad y control de cambios.
- Establecer pr√°cticas DevOps/DataOps para despliegue y monitoreo.
- Monitorear adopci√≥n y calidad de datos con herramientas de lineage.

---

## Conclusi√≥n

Esta arquitectura federada permite a la compa√±√≠a superar sus limitaciones actuales de integraci√≥n, disponibilidad y an√°lisis de datos. Gracias a servicios nativos de GCP, se logra una soluci√≥n moderna, segura, escalable y lista para habilitar tanto anal√≠tica descriptiva como casos de uso avanzados de inteligencia artificial y machine learning.

---

## Repositorio y Entrega

El c√≥digo, diagramas y documentaci√≥n se encuentran en el siguiente repositorio p√∫blico:  
üîó [https://github.com/juanperez/latam-challenge](https://github.com/juanperez/latam-challenge)
